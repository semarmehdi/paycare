# Guide de Configuration Jenkins et Pipeline CI/CD

## ğŸ“Œ Introduction

Ce projet implÃ©mente un pipeline CI/CD dans Jenkins pour exÃ©cuter un processus ETL en conteneur Docker. Le pipeline inclut des tests unitaires et envoie les rÃ©sultats sur AWS S3.

## ğŸ“‚ Structure du projet

```
â”œâ”€â”€ Jenkinsfile               # Pipeline Jenkins
â”œâ”€â”€ Dockerfile                # Conteneurisation du projet
â”œâ”€â”€ etl_process.py            # Script ETL principal
â”œâ”€â”€ test_etl.py               # Tests unitaires pour l'ETL
â”œâ”€â”€ upload_s3.py              # Script d'upload des rÃ©sultats sur S3
â”œâ”€â”€ requirements.txt          # DÃ©pendances Python
â””â”€â”€ data/
    â”œâ”€â”€ input_data.csv        # Fichier d'entrÃ©e pour l'ETL
    â”œâ”€â”€ output_data.csv       # RÃ©sultat du processus ETL
```

---

## ğŸš€ Ã‰tapes de configuration

### 1ï¸âƒ£ Configuration de Jenkins

Assurez-vous que Jenkins est bien installÃ© et fonctionne.

### 2ï¸âƒ£ Ajout des Variables d'Environnement

Les variables AWS pour l'upload sur S3 doivent Ãªtre ajoutÃ©es Ã  Jenkins.

1. **Aller dans Jenkins** â†’ **Manage Jenkins** â†’ **Manage Credentials**
2. SÃ©lectionnez **(global)** â†’ **Add Credentials**
3. Ajoutez les clÃ©s AWS en tant que **Secret Text**:
   - **AWS_ACCESS_KEY_ID**
   - **AWS_SECRET_ACCESS_KEY**

Ou ajoutez-les directement dans Jenkins :

1. **Aller dans Jenkins** â†’ **Manage Jenkins** â†’ **Configure System**
2. Ajoutez sous **Global Properties** â†’ **Environment Variables** :
   - `AWS_ACCESS_KEY_ID = VOTRE_CLE`
   - `AWS_SECRET_ACCESS_KEY = VOTRE_CLE_SECRET`

### 3ï¸âƒ£ Configuration du Job Jenkins

1. **CrÃ©er un nouveau job Jenkins** â†’ **Pipeline**
2. **SÃ©lectionner Pipeline Script from SCM**
3. **Ajouter le repository GitHub** contenant le `Jenkinsfile`
4. **Sauvegarder et exÃ©cuter**

---

## ğŸ—ï¸ Fonctionnement du Pipeline

### ğŸ› ï¸ Ã‰tapes du Pipeline :

1. **Clone du repository** : RÃ©cupÃ¨re le code depuis GitHub.
2. **ExÃ©cution des tests** :
   - Lance les tests dans un conteneur Docker.
   - Enregistre les rÃ©sultats en XML.
   - Envoie les rÃ©sultats sur S3.
3. **Build de l'ETL** :
   - Construit l'image Docker pour l'ETL.
4. **ExÃ©cution de l'ETL** :
   - Monte les fichiers CSV et exÃ©cute le traitement.
   - Sauvegarde le rÃ©sultat dans `data/output_data.csv`.

---

Ce pipeline CI/CD garantit l'intÃ©gration et le dÃ©ploiement automatisÃ© du processus ETL en utilisant Jenkins et Docker.

ğŸ”¥ N'hÃ©sitez pas Ã  adapter les configurations en fonction de votre environnement !
